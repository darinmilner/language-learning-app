pipeline {
    agent any

    def tfLib = evaluate readTrusted("groovy/terraformUtils.groovy")
    def commonLib = evaluate readTrusted("groovy/common.groovy")

    parameters {
        string(name: 'REPO_URL', defaultValue: 'https://github.com/your-username/your-repo.git', description: 'GitHub Repository URL')
        string(name: 'BUCKET_NAME', defaultValue: 'jenkins-terraform-bucket-123456', description: 'S3 Bucket Name')
        choice(name: 'AWS_REGION', choices: ['us-east-1', 'us-west-1', 'eu-west-1'], description: 'AWS Region')
        booleanParam(name: 'DESTROY_INFRASTRUCTURE', defaultValue: false, description: 'Destroy infrastructure instead of provisioning it')
    }

    environment {
        REGION = "${params.AWS_REGION}"
        BUCKET = "${params.BUCKET_NAME}"
        TF_STATE_KEY = "terraform.tfstate"
        HASH_KEY = "lambda_hash.txt"  // Key for the hash file in S3
        TF_DIR = 'Deployment/Terraform'
        NOTIFY_EMAIL = "youremail"
    }

    stages {
        stage("Clone Repo") {
            steps {
                echo "Cloning ${params.REPO_URL}"
                git url: "${params.REPO_URL}"
            }
        }

         stage("Print Selected AWS Region") {
            steps {
                echo "User selected AWS region: ${REGION}"
            }
        }

       stage('Setup AWS CLI') {
            steps {
                sh '''
                    python3 scripts/aws_setup.py
                    aws --version
                '''
            }
        }

        stage('Verify Login') {
            steps {
                sh 'aws sts get-caller-identity'
            }
        }

        stage('Generate Hash') {
            steps {
                checkout scm
                sh "chmod +x generate_hash.sh && ./scripts/generate_hash.sh"
            }
        }
    
        stage('Download Previous Hash') {
            steps {
                script {
                // Download previous hash from S3 (if exists)
                sh """
                    aws s3 cp "s3://${env.S3_BUCKET}/${env.HASH_KEY}" previous_hash.txt || true
                """
                }
            }
        }
    
        stage('Compare Hashes') {
            steps {
                script {
                    currentHash = readFile('lambda_hash.txt').trim()
                    previousHash = fileExists('previous_hash.txt') ? readFile('previous_hash.txt').trim() : ""
                    
                    if (currentHash == previousHash) {
                        // Skip deployment if hashes match
                        echo "Lambda code unchanged. Skipping Terraform deployment."
                        currentBuild.result = 'SUCCESS'
                        error("STOP_PIPELINE") // Halt pipeline gracefully
                    } else {
                        echo "Lambda code changed. Proceeding with deployment."
                    }
                }
            }
        }
    
        stage("Install Terraform") {
            steps {
                script {
                    tfLib.downloadTerraform()
                }
            }
        }

        stage('Upload New Hash') {
            steps {
                script {
                // Upload the new hash to S3
                sh "aws s3 cp lambda_hash.txt s3://${env.S3_BUCKET}/${env.HASH_KEY}"
                }
            }
        }

        // TODO: Add Email validation (AWS SNS)
        // stage('Initialize & Validate Terraform') {
        //     Result: SUCCESS
        //     URL: ${env.BUILD_URL}
        //     """,
        //         to: "${env.NOTIFY_EMAIL}"
        //     """
        // }

        // failure {
        //     emailext subject: "‚ùå Jenkins Build FAILED: ${env.JOB_NAME} #${env.BUILD_NUMBER}",
        //              body: """Build failed.

        //     Job: ${env.JOB_NAME}
        //     Build: #${env.BUILD_NUMBER}
        //     Result: FAILURE
        //     URL: ${env.BUILD_URL}
        //     """,
        //         to: "${env.NOTIFY_EMAIL}"
        // }
    }
}
